{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Restarted Python 3.11.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:\n",
      "(253680, 22)\n",
      "\n",
      "Frequency of each label value:\n",
      "Diabetes_012\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of the target:\n",
      "Diabetes_012\n",
      "0.0    0.842412\n",
      "2.0    0.139333\n",
      "1.0    0.018255\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Features:\n",
      "Index(['Diabetes_012', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
      "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
      "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
      "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
      "       'Income'],\n",
      "      dtype='object')\n",
      "Index(['Diabetes_012', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
      "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
      "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
      "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
      "       'Income'],\n",
      "      dtype='object')\n",
      "(253680, 17)\n",
      "Diabetes_012\n",
      "0.0    213703\n",
      "1.0     39977\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-9bd8f6f02692>:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, cols_to_scale] = bmi_scaler.transform(X[cols_to_scale])\n",
      "<ipython-input-1-9bd8f6f02692>:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[cols_to_scale] = gh_scaler.transform(X[cols_to_scale])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import (\n",
    "    Lasso,\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    "    Ridge,\n",
    "    SGDClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, minmax_scale\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import uniform,randint\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "relative_path = \"src\\diabetes.csv\"\n",
    "absolute_path = os.path.join(os.getcwd(), relative_path)\n",
    "with open(absolute_path, \"r\") as file:\n",
    "    df = pd.read_csv(absolute_path)\n",
    "# print(absolute_path)\n",
    "\n",
    "print(\"Dataset shape:\")\n",
    "print(df.shape)\n",
    "df.isnull().sum()\n",
    "print(\"\\nFrequency of each label value:\")\n",
    "print(df.Diabetes_012.value_counts())\n",
    "print(\"\\nDistribution of the target:\")\n",
    "print(df.Diabetes_012.value_counts(normalize=1))\n",
    "print(\"\\nFeatures:\")\n",
    "print(df.columns)\n",
    "df.Diabetes_012.replace(2.0, 1.0, inplace=True)\n",
    "print(df.columns)\n",
    "df.columns = df.columns.str.replace(\" \", \"\")\n",
    "df.drop(\n",
    "    [\"Fruits\", \"Veggies\", \"NoDocbcCost\", \"Education\", \"Income\"], axis=1, inplace=True\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]\n",
    "print(y.value_counts())\n",
    "bmi_scaler = StandardScaler()\n",
    "cols_to_scale = [\"BMI\"]\n",
    "bmi_scaler.fit(X[cols_to_scale])\n",
    "X.loc[:, cols_to_scale] = bmi_scaler.transform(X[cols_to_scale])\n",
    "# fig = X.hist(column=\"BMI\", figsize=(5, 5))\n",
    "# X.hist(column=\"GenHlth\", figsize=(5, 5))\n",
    "\n",
    "gh_scaler = StandardScaler()\n",
    "cols_to_scale = [\"GenHlth\"]\n",
    "gh_scaler.fit(X[cols_to_scale])\n",
    "X[cols_to_scale] = gh_scaler.transform(X[cols_to_scale])\n",
    "# X.hist(column=\"GenHlth\", figsize=(5, 5))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# X.hist(column=\"MentHlth\", figsize=(5, 5))\n",
    "\n",
    "ment_scaler = MinMaxScaler()\n",
    "cols_to_scale = [\"MentHlth\"]\n",
    "ment_scaler.fit(X[cols_to_scale])\n",
    "X[cols_to_scale] = ment_scaler.transform(X[cols_to_scale])\n",
    "# X.hist(column=\"MentHlth\", figsize=(5, 5))\n",
    "# X.hist(column=\"PhysHlth\", figsize=(5, 5))\n",
    "\n",
    "phys_scaler = MinMaxScaler()\n",
    "cols_to_scale = [\"PhysHlth\"]\n",
    "phys_scaler.fit(X[cols_to_scale])\n",
    "X[cols_to_scale] = phys_scaler.transform(X[cols_to_scale])\n",
    "# X.hist(column=\"PhysHlth\", figsize=(5, 5))\n",
    "# X.hist(column=\"Age\", figsize=(5, 5))\n",
    "\n",
    "age_scaler = MinMaxScaler()\n",
    "cols_to_scale = [\"Age\"]\n",
    "age_scaler.fit(X[cols_to_scale])\n",
    "X[cols_to_scale] = age_scaler.transform(X[cols_to_scale])\n",
    "# X.hist(column=\"Age\", figsize=(5, 5))\n",
    "# X.hist(column=\"Income\", figsize=(5, 5))\n",
    "# income_cat_to_avg_map = {\n",
    "#     1: 5,\n",
    "#     2: 12.5,\n",
    "#     3: 17.5,\n",
    "#     4: 22.5,\n",
    "#     5: 30.0,\n",
    "#     6: 42.5,\n",
    "#     7: 62.5,\n",
    "#     8: 75,\n",
    "# }\n",
    "# X = X.assign(Income=X.Income.map(income_cat_to_avg_map))\n",
    "# X.hist(column=\"Income\", figsize=(5, 5))\n",
    "# inc_scaler = MinMaxScaler()\n",
    "# cols_to_scale = [\"Income\"]\n",
    "# inc_scaler.fit(X[cols_to_scale])\n",
    "# X[cols_to_scale] = inc_scaler.transform(X[cols_to_scale])\n",
    "# X.hist(column=\"Income\", figsize=(5, 5))\n",
    "# X.hist(column=\"Education\", figsize=(5, 5))\n",
    "# edu_scaler = MinMaxScaler()\n",
    "# cols_to_scale = [\"Education\"]\n",
    "# edu_scaler.fit(X[cols_to_scale])\n",
    "# X[cols_to_scale] = edu_scaler.transform(X[cols_to_scale])\n",
    "# X.hist(column=\"Education\", figsize=(5, 5))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.2, random_state=1\n",
    "# )\n",
    "# pd.Series(y_test).value_counts().plot(kind=\"bar\")\n",
    "\n",
    "# smt = SMOTE(random_state=1)\n",
    "# X_train, y_train = smt.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.90      0.89     42798\n",
      "         1.0       0.39      0.36      0.37      7938\n",
      "\n",
      "    accuracy                           0.81     50736\n",
      "   macro avg       0.64      0.63      0.63     50736\n",
      "weighted avg       0.81      0.81      0.81     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0,class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "# y_pred_val = rf.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.72      0.82     42798\n",
      "         1.0       0.34      0.76      0.47      7938\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.64      0.74      0.64     50736\n",
      "weighted avg       0.85      0.73      0.76     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver=\"newton-cholesky\", random_state=0, penalty=\"l2\",C=0.5)\n",
    "lr.fit(X_train, y_train)\n",
    "# y_pred_val = lr.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.72      0.82     42798\n",
      "         1.0       0.34      0.76      0.47      7938\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.64      0.74      0.64     50736\n",
      "weighted avg       0.85      0.73      0.76     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver=\"newton-cholesky\", random_state=0, penalty=\"l2\",C=0.3)\n",
    "lr.fit(X_train, y_train)\n",
    "# y_pred_val = lr.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.72      0.82     42798\n",
      "         1.0       0.34      0.76      0.47      7938\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.64      0.74      0.64     50736\n",
      "weighted avg       0.85      0.73      0.76     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver=\"newton-cholesky\", random_state=0, penalty=\"l2\",C=5)\n",
    "lr.fit(X_train, y_train)\n",
    "# y_pred_val = lr.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.72      0.82     42798\n",
      "         1.0       0.34      0.76      0.47      7938\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.64      0.74      0.64     50736\n",
      "weighted avg       0.85      0.73      0.76     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', random_state=0, penalty=\"l2\",C=5)\n",
    "lr.fit(X_train, y_train)\n",
    "# y_pred_val = lr.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.67      0.79     42798\n",
      "         1.0       0.31      0.81      0.45      7938\n",
      "\n",
      "    accuracy                           0.69     50736\n",
      "   macro avg       0.63      0.74      0.62     50736\n",
      "weighted avg       0.85      0.69      0.73     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sv = SGDClassifier(random_state=0)\n",
    "sv.fit(X_train, y_train)\n",
    "# y_pred_val = sv.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = sv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.87      0.87     42798\n",
      "         1.0       0.32      0.33      0.32      7938\n",
      "\n",
      "    accuracy                           0.79     50736\n",
      "   macro avg       0.60      0.60      0.60     50736\n",
      "weighted avg       0.79      0.79      0.79     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "# y_pred_val = dt.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = dt.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91     42798\n",
      "         1.0       0.48      0.31      0.38      7938\n",
      "\n",
      "    accuracy                           0.84     50736\n",
      "   macro avg       0.68      0.62      0.64     50736\n",
      "weighted avg       0.82      0.84      0.83     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg = XGBClassifier(random_state=0)\n",
    "xg.fit(X_train, y_train)\n",
    "# y_pred_val = xg.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = xg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.72      0.82     42798\n",
      "         1.0       0.33      0.74      0.46      7938\n",
      "\n",
      "    accuracy                           0.72     50736\n",
      "   macro avg       0.63      0.73      0.64     50736\n",
      "weighted avg       0.84      0.72      0.76     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml = MLPClassifier(random_state=0)\n",
    "ml.fit(X_train, y_train)\n",
    "# y_pred_val = ml.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = ml.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 0.5, 'max_iter': 200, 'penalty': 'l1', 'solver': 'saga'}\n",
      "F1-score on test set:  0.7629613698627573\n"
     ]
    }
   ],
   "source": [
    "logistic_reg = LogisticRegression()\n",
    "# Define the parameter grid to search over\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 0.2, 0.5, 1, 5, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 200],\n",
    "}\n",
    "# Create a GridSearchCV object\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logistic_reg,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',  # Use F1-score as the scoring metric\n",
    "    cv=5,\n",
    "    refit=True\n",
    ")\n",
    "# Fit the GridSearchCV object to the training data\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Print the best parameters found\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "# Evaluate the best model on the testing data and calculate the F1-score\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1-score on test set: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'color': ['red', 'blue', 'green', 'red', 'green']}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoder.fit_transform(df[['color']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['color']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df, df_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color  color_blue  color_green  color_red\n",
      "0    red         0.0          0.0        1.0\n",
      "1   blue         1.0          0.0        0.0\n",
      "2  green         0.0          1.0        0.0\n",
      "3    red         0.0          0.0        1.0\n",
      "4  green         0.0          1.0        0.0\n"
     ]
    }
   ],
   "source": [
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'color': ['red', 'blue', 'green', 'red', 'green']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color\n",
       "0    red\n",
       "1   blue\n",
       "2  green\n",
       "3    red\n",
       "4  green"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'color': ['red', 'blue', 'green', 'red', 'green']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color\n",
       "0    red\n",
       "1   blue\n",
       "2  green\n",
       "3    red\n",
       "4  green"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoder.fit_transform(df[['color']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit_transform(df[['color']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "No kernel connected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
